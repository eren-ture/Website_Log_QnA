{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from config import openai_key, claude_key\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status2desc_dict = {\n",
    "    100: \"Continue\",\n",
    "    101: \"Switching Protocols\",\n",
    "    102: \"Processing\",\n",
    "    103: \"Early Hints\",\n",
    "    \n",
    "    200: \"OK\",\n",
    "    201: \"Created\",\n",
    "    202: \"Accepted\",\n",
    "    203: \"Non-Authoritative Information\",\n",
    "    204: \"No Content\",\n",
    "    205: \"Reset Content\",\n",
    "    206: \"Partial Content\",\n",
    "    207: \"Multi-Status\",\n",
    "    208: \"Already Reported\",\n",
    "    226: \"IM Used\",\n",
    "    \n",
    "    300: \"Multiple Choices\",\n",
    "    301: \"Moved Permanently\",\n",
    "    302: \"Found\",\n",
    "    303: \"See Other\",\n",
    "    304: \"Not Modified\",\n",
    "    305: \"Use Proxy\",\n",
    "    306: \"(Unused)\",\n",
    "    307: \"Temporary Redirect\",\n",
    "    308: \"Permanent Redirect\",\n",
    "    \n",
    "    400: \"Bad Request\",\n",
    "    401: \"Unauthorized\",\n",
    "    402: \"Payment Required\",\n",
    "    403: \"Forbidden\",\n",
    "    404: \"Not Found\",\n",
    "    405: \"Method Not Allowed\",\n",
    "    406: \"Not Acceptable\",\n",
    "    407: \"Proxy Authentication Required\",\n",
    "    408: \"Request Timeout\",\n",
    "    409: \"Conflict\",\n",
    "    410: \"Gone\",\n",
    "    411: \"Length Required\",\n",
    "    412: \"Precondition Failed\",\n",
    "    413: \"Payload Too Large\",\n",
    "    414: \"URI Too Long\",\n",
    "    415: \"Unsupported Media Type\",\n",
    "    416: \"Range Not Satisfiable\",\n",
    "    417: \"Expectation Failed\",\n",
    "    418: \"I'm a teapot\",\n",
    "    421: \"Misdirected Request\",\n",
    "    422: \"Unprocessable Entity\",\n",
    "    423: \"Locked\",\n",
    "    424: \"Failed Dependency\",\n",
    "    425: \"Too Early\",\n",
    "    426: \"Upgrade Required\",\n",
    "    428: \"Precondition Required\",\n",
    "    429: \"Too Many Requests\",\n",
    "    431: \"Request Header Fields Too Large\",\n",
    "    451: \"Unavailable For Legal Reasons\",\n",
    "    \n",
    "    500: \"Internal Server Error\",\n",
    "    501: \"Not Implemented\",\n",
    "    502: \"Bad Gateway\",\n",
    "    503: \"Service Unavailable\",\n",
    "    504: \"Gateway Timeout\",\n",
    "    505: \"HTTP Version Not Supported\",\n",
    "    506: \"Variant Also Negotiates\",\n",
    "    507: \"Insufficient Storage\",\n",
    "    508: \"Loop Detected\",\n",
    "    510: \"Not Extended\",\n",
    "    511: \"Network Authentication Required\"\n",
    "}\n",
    "\n",
    "for key, desc in status2desc_dict.items():\n",
    "\n",
    "    if key / 100 >= 5:\n",
    "        status2desc_dict[key] = f\"{key} [server error] {status2desc_dict[key]}\"\n",
    "    elif key / 100 >= 4:\n",
    "        status2desc_dict[key] = f\"{key} [client error] {status2desc_dict[key]}\"\n",
    "    elif key / 100 >= 3:\n",
    "        status2desc_dict[key] = f\"{key} [redirection] {status2desc_dict[key]}\"\n",
    "    elif key / 100 >= 2:\n",
    "        status2desc_dict[key] = f\"{key} [success] {status2desc_dict[key]}\"\n",
    "    else:\n",
    "        status2desc_dict[key] = f\"{key} [info] {status2desc_dict[key]}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './apache_logs.txt'\n",
    "matches = []\n",
    "\n",
    "#              IP              ts        Request Status Size   Referrer User-Agent\n",
    "rx_pattern = r'([(\\d\\.)]+) - - \\[(.*?)\\] \"(.*?)\" (\\d+) (\\d+|-) \"(.*?)\" \"(.*?)\"'\n",
    "\n",
    "with open(log_dir) as log:\n",
    "    for line in log:\n",
    "        match = re.match(rx_pattern, line)\n",
    "        if match:\n",
    "            matches.append(match.groups())\n",
    "        else:\n",
    "            print(line)\n",
    "\n",
    "columns = [\"IP\", \"Timestamp\", \"Request\", \"Status\", \"Size\", \"Referrer\", \"User-Agent\"]\n",
    "df = pd.DataFrame(matches, columns=columns)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%d/%b/%Y:%H:%M:%S %z')\n",
    "df['Size'] = pd.to_numeric(df['Size'], errors='coerce').fillna(0).astype(int)\n",
    "df['Status'] = df['Status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = df.copy()\n",
    "emb_df['Request'] = df['Request'].apply(lambda x: f\"Request: {x}\")\n",
    "emb_df['Status-Description'] = df['Status'].apply(lambda x: f\"Status: {status2desc_dict[x]}\")\n",
    "emb_df['Referrer'] = df['Referrer'].apply(lambda x: f\"Referrer: {x}\")\n",
    "emb_df['User-Agent'] = df['User-Agent'].apply(lambda x: f\"User-Agent: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('multi-qa-distilbert-dot-v1')\n",
    "indices_dir = 'indices'\n",
    "emb_cols = ['Request', 'Status-Description', 'Referrer', 'User-Agent']\n",
    "\n",
    "if not os.path.isdir(indices_dir):\n",
    "\n",
    "    print('Indices do not exist, embedding values.')\n",
    "\n",
    "    os.makedirs(indices_dir)\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = dict()\n",
    "    for col in emb_cols:\n",
    "        embeddings[col] = model.encode(emb_df[col])\n",
    "\n",
    "    # Init FAISS index shape with the first column\n",
    "    doc_len, emb_dim = list(embeddings.values())[0].shape\n",
    "\n",
    "    indices = dict()\n",
    "    for col, emb in embeddings.items():\n",
    "        indices[col] = faiss.IndexFlatL2(emb_dim)\n",
    "        indices[col].add(emb)\n",
    "        faiss.write_index(indices[col], os.path.join(indices_dir, f\"faiss_{col}_index.bin\"))\n",
    "\n",
    "    print('Indices Created:')\n",
    "    print(indices.keys())\n",
    "\n",
    "else:\n",
    "\n",
    "    doc_len = len(emb_df)\n",
    "    print('Found indices, loading embeddings.')\n",
    "\n",
    "    # Load the saved file to index\n",
    "    indices = dict()\n",
    "    for pth in os.listdir(indices_dir):\n",
    "        indices[pth.split('_')[1]] = faiss.read_index(os.path.join(indices_dir, pth))\n",
    "\n",
    "    print('Indices Loaded:')\n",
    "    print(indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query, max_lines=25):\n",
    "\n",
    "    def calculate_distances(query_embedding, indices):\n",
    "\n",
    "        # Initialize results dictionary\n",
    "        distances = dict()\n",
    "        # Search in each index\n",
    "        for key, index in indices.items():\n",
    "            dts, idx = index.search(np.array([query_embedding]), k=doc_len)\n",
    "            distance = np.array(sorted(zip(idx[0], dts[0]), key = lambda x: x[0]))[:,1]    # All distances sorted by index\n",
    "            distances[key] = distance\n",
    "\n",
    "        return distances\n",
    "    \n",
    "    # Search only for specific ip(s), if found in query\n",
    "    ip_pattern = r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b'\n",
    "    query_ips = re.findall(ip_pattern, query)\n",
    "\n",
    "    # Embed and calculate vector distances\n",
    "    query_embedding = model.encode(query, convert_to_numpy=True)\n",
    "    dist_dict = calculate_distances(query_embedding, indices)\n",
    "\n",
    "    disp_df = df.copy()\n",
    "\n",
    "    for key, dists in dist_dict.items():\n",
    "        disp_df[f'{key}_distance'] = dists\n",
    "\n",
    "    disp_df['distances_mean'] = disp_df[[f'{nm}_distance' for nm in emb_cols]].mean(axis=1)\n",
    "\n",
    "    if query_ips:\n",
    "        disp_df = disp_df[emb_df['IP'].isin(query_ips)].sort_values('distances_mean', ascending=True)\n",
    "    else:\n",
    "        disp_df = disp_df.sort_values('distances_mean', ascending=True)\n",
    "\n",
    "    # Debug\n",
    "    display(disp_df.head())\n",
    "    print(disp_df.shape)\n",
    "\n",
    "    if len(disp_df) == 0:\n",
    "        return \"No log found with given information.\"\n",
    "    else:\n",
    "        return disp_df.iloc[:max_lines,:7].to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Status'] == 404]['IP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_context(\"SQL injection\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat():\n",
    "\n",
    "    def __init__(self, system_text):\n",
    "        self.client = Anthropic(api_key=claude_key)\n",
    "        self.system = system_text\n",
    "        self.messages = []\n",
    "\n",
    "    def __call__(self, message, context=None):\n",
    "\n",
    "        # Initialize current message by the user\n",
    "        curr_msg = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": []\n",
    "        }\n",
    "\n",
    "        # Add context if available\n",
    "        if context:\n",
    "            curr_msg[\"content\"].append({\"type\": \"text\", \"text\": context})\n",
    "\n",
    "        # Add user message\n",
    "        curr_msg[\"content\"].append({\"type\": \"text\", \"text\": message})\n",
    "\n",
    "        # Append the message to the conversation\n",
    "        self.messages.append(curr_msg)\n",
    "\n",
    "        # Get response from the API\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20240620\",\n",
    "            max_tokens=1000,\n",
    "            temperature=0,\n",
    "            system=self.system,\n",
    "            messages=self.messages\n",
    "        )\n",
    "\n",
    "        # Initialize agent message\n",
    "        agent_response_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": response.content[0].text}]\n",
    "        }\n",
    "\n",
    "        # Append response to conversation\n",
    "        self.messages.append(agent_response_message)\n",
    "\n",
    "        # print(json.dumps(self.messages, indent=4))\n",
    "\n",
    "        # Return agent response to be printed\n",
    "        return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(\"You are a web security expert. You are tasked with analysing web logs and answering to questions/inquiries. A table to logs in csv format is given.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Write your inquiry. Write \\'esc\\' to quit.\")\n",
    "for i in range(10):\n",
    "    print(\"> \", end=\"\")\n",
    "    u_msg = input()\n",
    "\n",
    "    if u_msg == \"esc\":\n",
    "        break\n",
    "\n",
    "    print(u_msg)\n",
    "\n",
    "    if i == 0:\n",
    "        print(chat(u_msg, get_context(u_msg)))\n",
    "    else:\n",
    "        print(chat(u_msg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
